{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy Tutorial\n",
    "\n",
    "\n",
    "**Note:**\n",
    "1. Mandatory pre-requisite reading: Chapter 4 from \"Python for Data Science Handbook\" by Jake Vanderplas\n",
    "2. Numpy Documentation - User Guide & API Reference: https://numpy.org/doc/stable/\n",
    "3. Cautionary Note: Watch out for the version of numpy you are using and the documentation you are referring\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "**Numpy Intro**\n",
    "1. [Size of python data types](#python-datatypes-size)\n",
    "2. [Perils of using Python data type & global function names as variable names](#perils)\n",
    "3. [Starting with Numpy](#numpy-start)\n",
    " \n",
    "**Numpy Operations: Indexing & Slicing**\n",
    "1. [Numpy Reshape](#reshape)\n",
    "2. [Array Indexing in numpy](#indexing)\n",
    "3. [Looping and Slicing in Python iterable data types](#python-looping-slicing)\n",
    "4. [Numpy slicing](#numpy-slicing)\n",
    "5. [Slicing 2D array (2D Data Matrix) as features and samples](#sample-feature-slicing)\n",
    "6. [Using Numpy slicing in your first ML model training](#numpy-slicing-first-ml)\n",
    "7. [Exercise1 - Manually select best features](#exercise1)\n",
    "\n",
    "**Numpy Operations: Vectorization, Universal functions & Broadcasting**\n",
    "1. [Power of vectorization](#vector-power)\n",
    "2. [Universal Functions (ufuncs) - Built-in vectorized operations](#ufunc)\n",
    "3. [3 basic vector operations - Vector addition, subtraction & scalar multiplication](#add-minus-multiply)\n",
    "4. [Comparison operators and boolean mask based indexing](#masking)\n",
    "5. [Aggregation functions](#aggr-functions)\n",
    "6. [Average Patient calculation](#avg-patient)\n",
    "7. [Broadcasting](#broadcasting)\n",
    "8. [Farthest patient from mean patient](#farthest-patient)\n",
    "9. [Feature transformation in sklearn](#scaler-tx)\n",
    "10. [Calculating farthest patients from each other](#farthest-patients)\n",
    "\n",
    "\n",
    "**The following sections are for later**\n",
    "\n",
    "**Numpy Random generators will be provided in a separate notebook at appropriate time during EDA, clustering** \n",
    "\n",
    "**Dot Product, Matrix operations**\n",
    "1. [Dot product vectorization](#dotproduct)\n",
    "2. [Norm as dot product](#norm-dot)\n",
    "3. [Digression: Plotting]()\n",
    "4. [Sigmoid and Softmax with vectorization, broadcasting]() E.g. neural network\n",
    "5. [Vector dot product identities](#dot-identity) \n",
    "6. [Matrix Multiplication]()\n",
    "7. [Matrix (Frobenius) Norm]()\n",
    "8. [Matrix norm identity](#matmul-identity)\n",
    "\n",
    "References:\n",
    "1. https://towardsdatascience.com/python-lists-vs-numpy-arrays-a-deep-dive-into-memory-layout-and-performance-benefits-a74ce774bc1e\n",
    "2. https://www.digitalocean.com/community/tutorials/python-numpy-where\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='python-datatypes-size'></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Intro\n",
    "\n",
    "#### 1. Sizes of Python data types\n",
    "\n",
    "##### 1.1 Simple data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python numbers are inferred, Numpy numbers can be inferred or specified \n",
    "counter = 0\n",
    "\n",
    "# We can provide PEP484 type hints.\n",
    "# NOTE: This is for human readability only\n",
    "# Python wont complain even if you put a invalid type hint\n",
    "counter: int = 0\n",
    "\n",
    "# Python is implemented in C\n",
    "# A Data Type in Python is a data structure in C\n",
    "\n",
    "# We can find the memory location of a python variable like this\n",
    "id(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Memory address of counter variable is {id(counter)}\") \n",
    "\n",
    "# what is the size of int datatype in bytes?\n",
    "import sys\n",
    "sys.getsizeof(counter) #whopping 24 (28) bytes (not bits) to store a number !!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python versus C variable memory storage comparison\n",
    "\n",
    "![Python C meory variable storage comparison](https://onedrive.live.com/embed?resid=A5A4158EF1352FCB%211877&authkey=%21AMgFrEM_cJYzebQ&width=686&height=221)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Collection data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python list can hold mixed type of data \n",
    "# Data may not be stored sequentially stored at different locations \n",
    "l = [1,2,3,4,5,'abc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 Finding the length of a collection data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3,4,5,'abc']\n",
    "\n",
    "print(len(l)) #len() function is implemented by many python types and data structures\n",
    "\n",
    "# Check the memory address of adjacent items in list. Are they adjacent in memory?\n",
    "print(id(l[0]))\n",
    "print(id(l[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second verification if list items are contiguous \n",
    "# Lets find the size of each item \n",
    "# Then see if the above memory address for l[0] and l[1] are contiguous \n",
    "sys.getsizeof(l[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storage of python lists in memory. Notice the storage of data type redundantly on every python list since list is supposed to allow all kinds of data types. This convenience comes at a huge cost making it unsuitable for large scale numerical data processing \n",
    "\n",
    "![Python mempry List in memory](https://onedrive.live.com/embed?resid=A5A4158EF1352FCB%211875&authkey=%21AKSvuHVLDRrqXH4&width=770&height=393)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4 Python dense array\n",
    "\n",
    "1. Gives efficient storage compared to List\n",
    "2. But no efficient operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array\n",
    "\n",
    "list2 = [1,2,3,4,5] # A list with same data type\n",
    "\n",
    "darray = array.array(\"i\", list2) # here i stands for integer data type\n",
    "darray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(darray[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![python array syntax](https://www.softwaretestinghelp.com/wp-content/qa/uploads/2021/04/fig2_syntax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='perils'></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Perils of using Python data type & global function names as variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list()\n",
    "a.append(\"Hello\")\n",
    "type(a)\n",
    "\n",
    "list = \"Hello\" # This is WRONG. DO not use python global function names and data types as variable names\n",
    "b = list() #Can you tell why this line gives errors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do you want to do something even more destructive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 10\n",
    "y = str(10)\n",
    "print(y)\n",
    "\n",
    "str = \"hello world\"\n",
    "y = str(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Moral of the Story\n",
    "\n",
    "1. Do not name your variable/function with python functions or datatype names\n",
    "2. Python will not complain if you do so.\n",
    "3. But from that point onwards, your python will be completely messed. \n",
    "4. Every invocation may get redirected to the re-definition\n",
    "\n",
    "5. Also do not reuse variable and function names in your own application space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"numpy-start\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Starting with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__ #Check the numpy version for sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 numpy data types\n",
    "\n",
    "1. numpy maintains a separate set of data types other than python\n",
    "2. There are around 24 data types in all (in latest version of numpy) - See Jake Vanderplas 4th chapter as you read later\n",
    "\n",
    "![python array syntax](https://numpy.org/doc/stable/_images/dtype-hierarchy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 numpy creation with inferred data type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,5,-8]) #Data type of individual entries is inferred automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(a)) # print the data type of the numpy array\n",
    "\n",
    "print(type(a[0])) # print the data type of first element numpy array\n",
    "\n",
    "# Alternate way of getting the data type of entries of numpy array\n",
    "print(a.dtype)\n",
    "\n",
    "print(a.strides) #Ans the question: what is strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([1.0, 2.0, 3.0]) #data type is inffered to be float due to the decimal point\n",
    "b.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 Cautionary Digression: Printable representation are never indication of data type  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,5,-8])\n",
    "a # this uses repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of print function on a numpy array is very misleading\n",
    "# Output makes you feel as if it is a list, but it is not\n",
    "print(a)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do a print and repr on a list to compare\n",
    "int_list = [ 1,  2,  3,  5, -8]\n",
    "\n",
    "print(int_list)\n",
    "int_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4 Explicitly specifying data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of specified type\n",
    "b = np.array([1, 2, 3], dtype='f')\n",
    "\n",
    "print(f\"b.dtype={b.dtype}\") #This will show float32\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,5,-8])\n",
    "a.astype(np.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the int array into float array\n",
    "a.astype(float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what happened here? Why is numpy array a not showing as float anymore \n",
    "# hint: astype() operation is NOT in-place modification\n",
    "a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct way \n",
    "new_arr = a.astype(float)\n",
    "new_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5 Why so much stress on data type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "        \"intfield1\":[4,5,6,10,12],\n",
    "        \"intfield2\":[100,101,102,103,104],\n",
    "        \"floatfield1\":[4.0,5.0,6,10,12],\n",
    "        \"floatfield2\":[9.0,10.0,11,12,13],\n",
    "        \"intfield3\":[95,96,97,98,98]\n",
    "        })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "        (4,100,4.0,9.0,95),(5,101,5.0,10.0,96), (6,102,6.0,11,97), \n",
    "        (10,103,10.0,12,98), (12,104,12.0,13,98)],\n",
    "    dtype=[(\"intfield1\", \"i1\"), (\"intfield2\", \"i1\"), (\"floatfield1\", 'f2'), \n",
    "            (\"floatfield2\", 'f2'),(\"intfield3\", \"i1\")])\n",
    "df = pd.DataFrame(data, columns=[\"intfield1\", \"intfield2\", \"floatfield1\", \"floatfield2\", \"intfield3\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage=\"deep\") #50% savings in data compared to inferred type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy operations: Indexing & Slicing\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"reshape\"></a>\n",
    "### 1. Numpy Vector reshape()\n",
    "\n",
    "##### 1.1 Why and how to reshape 1D numpy array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,5,-8])\n",
    "print(a.shape)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_transpose = a.T  # This transpose never works. why?\n",
    "print(a_transpose.shape)\n",
    "a_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,5,-8]).reshape(-1,1)\n",
    "print(a.shape)\n",
    "print(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_transpose = a.T  # This transpose works. why?\n",
    "print(a_transpose.shape)\n",
    "a_transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Creating & reshaping a 2D numpy array\n",
    "\n",
    "Consider a 2D array (matrix in Linear Algebra) as follows \n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1& 2 & 3 \\\\\n",
    "4 & 4 & 6\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "How to represent in numpy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Display the array\n",
    "print(a)\n",
    "\n",
    "# Attributes of the array\n",
    "# Shape of the array\n",
    "print(a.shape)\n",
    "\n",
    "# Data type of array elements\n",
    "print(a.dtype)\n",
    "\n",
    "# What type of object is the variable 'a'?\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In memory storage of numpy. Notice that data is stored contiguously, while numpy provides an illusion of rows and columns\n",
    "\n",
    "![Row ordering](https://onedrive.live.com/embed?resid=A5A4158EF1352FCB%211874&authkey=%21ANDTtRbLA1nfJRk&width=745&height=338)\n",
    "\n",
    "While storing contiguously, notice the use of single data type and maintaining the dimension and strides (strides)\n",
    "\n",
    "![mem storage](https://onedrive.live.com/embed?resid=A5A4158EF1352FCB%211876&authkey=%21ALdr2sOFYWOpqdY&width=781&height=198)\n",
    "\n",
    "Row strides determine where to jump for the next row within contiguous memory. column stride determines the jump for next column\n",
    "\n",
    "![np internal](https://onedrive.live.com/embed?resid=A5A4158EF1352FCB%211867&authkey=%21AGX6nCSb-QQjaYc&width=660)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten a 2D array\n",
    "# Question: Where will this be possibly used?\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "a_flat = a.flatten()\n",
    "print(a_flat.shape)\n",
    "a_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten a 2D array\n",
    "# Where will this be possibly used?\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "a_colvector = a.reshape(?,?) #TODO: Fill this\n",
    "print(a_colvector.shape)\n",
    "a_colvector #Compare the shape of this col vector with a_flat in previous cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a_colvector.reshape(3,2)) # 3x2 matrix\n",
    "print(a_colvector.reshape(2,3)) # 2x3 matrix\n",
    "print(a_colvector.reshape(1,6)) #row vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"indexing\"></a>\n",
    "### 2. Array Indexing in numpy\n",
    "\n",
    "##### 2.1 1D array indexing in numpy\n",
    "![Numpy 1DArray Indexing](https://numpy.org/doc/stable/_images/np_indexing.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(a)\n",
    "\n",
    "print(a[0])\n",
    "print(a[1])\n",
    "\n",
    "print(a[-1]) # first element from the tail of the array\n",
    "print(a[-2]) # second element from the tail of the array\n",
    "\n",
    "#print(a[5]) # throws an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 2D array indexing in numpy\n",
    "\n",
    "$$\n",
    "  \\begin{bmatrix}\n",
    "    1 & 2 \\\\\n",
    "    3 & 4 \\\\\n",
    "    5 & 6 \\\\\n",
    "    7 & 8\n",
    "  \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "print(a)\n",
    "print('----')\n",
    "print(a[0, 0])\n",
    "print(a[-1, 0])\n",
    "print(a[0, -1])\n",
    "print(a[-1, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2D array indexing](https://numpy.org/doc/stable/_images/np_matrix_indexing.png)\n",
    "<a id=\"python-looping-slicing\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Looping and Slicing in Python iterable data types\n",
    "\n",
    "1. Looping with range\n",
    "2. Direct looping over list\n",
    "3. Looping with enumerate\n",
    "4. Co-iterating over two lists simulatenously with zip\n",
    "5. List slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Looping with range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does range do?\n",
    "# iterates from starting point to one less than specifed value\n",
    "# C equivalent is for(i = 0; i< 3; i++)\n",
    "for i in range(3):\n",
    "    print(i, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,10,2): # C equivalent is for(i=2; i<10; i=i+2)\n",
    "    print(i, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Looping over List: Many ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct list iteration\n",
    "\n",
    "# We will iterate over the list to add items to a new list\n",
    "lst = [1,2,3,4,5,'abc']\n",
    "lst_new = []\n",
    "\n",
    "for item in lst:\n",
    "    print(item, end = \" \")\n",
    "    lst_new.append(item)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"length = {len(lst)}\")\n",
    "\n",
    "#print lst_new\n",
    "print(lst_new)\n",
    "\n",
    "# ensure the memory address of lst and lst_new are different\n",
    "lst is lst_new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [1,2,3,4,5,'abc']\n",
    "\n",
    "# Using range without a starting point\n",
    "# uses 0 as the starting point\n",
    "for i in range(len(lst)):\n",
    "    print(lst[i], end=\" \")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Using range with a starting point\n",
    "for i in range(3, len(lst)):\n",
    "    print(lst[i], end=\" \")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Using range with a starting, ending point and step size\n",
    "for i in range(2, len(lst), 2):\n",
    "    print(lst[i], end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 Looping over list with enumerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerate gives a tuple\n",
    "lst = [1,2,3,4,5,'abc']\n",
    "for tpl in enumerate(lst):\n",
    "    print(tpl, end=\" \") # each tuple gives looping index and the actual item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using enumerate gives access to the index variable\n",
    "for i, item in enumerate(lst): #Format for unpacking a tuple format\n",
    "    print(f\"Looping Index = {i}, Item = {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4 Co-iterating over two lists with zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using zip function to iterate two related sequences\n",
    "# Usage: zip(iterator1, iterator2, iterator3 ...)\n",
    "\n",
    "people = [\"Vishwas\", \"Akarsh\", \"Mohit\", \"Aditya\", \"Rakshit\"]\n",
    "salary_in_lakhs = [19, 9.5, 10, 12, 14]\n",
    "\n",
    "for person, salary in zip(people, salary_in_lakhs):\n",
    "    print(f\"{person} {salary} lakhs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5 python list slicing\n",
    "\n",
    "1. Slicing can be done for anything iterable - including strings\n",
    "2. In languages like C, we have to iterate over a list to create a sublist. In python it can be achieved with slicing\n",
    "3. Numpy slicing is similar to List slicing. \n",
    "4. <font color=\"red\">List slicing creates a new sub list. Changing the values in the original list or sublist does not impact the other</font>\n",
    "5. <font color=\"red\">HOWEVER: Numpy array slicing is a view over the original array. Changing the values in the sliced or original array reflects both ways</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing a list \n",
    "lst = [1,2,3,4,5,'abc']\n",
    "lst_first_3 = lst[0:3]\n",
    "lst_first_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing a list \n",
    "lst = [1,2,3,4,5,'abc']\n",
    "lst_odd_ones = lst[0:5:2] # slicing format is start:end:step\n",
    "lst_odd_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the value in sublist does not impact the main list\n",
    "lst_odd_ones[0] = 100\n",
    "print(lst_odd_ones)\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing a list with steps\n",
    "lst = [1,2,3,4,5,'abc']\n",
    "lst_jump2 = lst[0::2] # if end is not specified in start:end:step, then implicitly, the real end of list is used\n",
    "lst_jump2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing and skip last\n",
    "lst = [1,2,3,4,5,'abc']\n",
    "lst_skiplast = lst[0:-1] # the step size of -1 indicates stepping backwards\n",
    "lst_skiplast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reversing a list\n",
    "lst = [1,2,3,4,5,'abc']\n",
    "lst_reverse = lst[::-1]\n",
    "lst_reverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"numpy-slicing\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Numpy slicing\n",
    "\n",
    "**Efficient Storage**\n",
    "One of the reasons why slicing in Numpy is faster than python list is because it uses view (by reference) instead of copy by value\n",
    "\n",
    "![Copy versus view](https://onedrive.live.com/embed?resid=A5A4158EF1352FCB%211880&authkey=%21AG4XBNxLlBD5N64&width=827&height=420)\n",
    "\n",
    "**Cache Locality**\n",
    "\n",
    "Another factor for numpy speed is Cache Locality. \n",
    "\n",
    "1. NumPy’s contiguous memory layout helps improve cache hit rates as it matches how CPU caches work\n",
    "2. A CPU cache is a small, high-speed storage area between the CPU and main memory (RAM). The purpose of the CPU cache is to speed up data access in memory. When the CPU needs to read or write data, it first checks if it is already in the cache.\n",
    "\n",
    "![Cache](https://onedrive.live.com/embed?resid=A5A4158EF1352FCB%211878&authkey=%21AApNmHJsodNzIqE&width=591&height=202)\n",
    "\n",
    "3. CPU caches are usually organized in cache lines, which are contiguous memory addresses. When the CPU accesses RAM, the cache loads the entire cache line into the high-speed cache. if the CPU accesses neighboring memory addresses, subsequent accesses are more likely to hit the cache after loading a cache line, thus improving performance.\n",
    "\n",
    "![Cache Line](https://onedrive.live.com/embed?resid=A5A4158EF1352FCB%211879&authkey=%21AMiRIS2afDtI4CM&width=625&height=264)\n",
    "\n",
    "4. NumPy arrays store data in continuous memory addresses, which helps improve cache locality. When accessing an element in the array, the entire cache line (containing neighboring array elements) is loaded into the cache. As you traverse the array, you access each element in a sequence. Because array elements are stored contiguously in memory, cache hits are more likely during the traversal, improving performance.\n",
    "\n",
    "##### 4.1 1D array slicing in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(a)\n",
    "\n",
    "print('-----')\n",
    "\n",
    "# Get all elements of the array\n",
    "print(a[:])\n",
    "\n",
    "# Specify a slice with start and end indices\n",
    "print(a[:3])\n",
    "print(a[1:3])\n",
    "print(a[2:])\n",
    "print(a[:-1]) # skips the tail element of the array\n",
    "\n",
    "print(a[-3:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[0:-1:2]) # start from first element, skip the last element, jump by 2\n",
    "print(a[0::2]) # start from first element, include the last element, jump by 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Numpy sliced array data are views over the same memory reference\n",
    "\n",
    "1. Sliced numpy array variable has different memory reference\n",
    "2. But sliced numpy array *data* is a view over the same memory reference of parent \n",
    "<font color=\"red\">Very important point to know</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(\"\\nArray a:\")\n",
    "print(a)\n",
    "\n",
    "b = a[-3:-1]\n",
    "print(\"\\bArray b:\")\n",
    "print(b)\n",
    "\n",
    "print(f\"a and b reference same address ? {a is b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = a[-3:-1]\n",
    "\n",
    "a[3] = 100\n",
    "print(\"\\nArray b after a is modified:\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = a[-3:-1]\n",
    "\n",
    "b[0] = 999\n",
    "print(\"\\nArray a after b is modified:\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing creates views. Many times it is desirable to maintain single copy. However, sometimes we want force a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = a[-3:-1].copy()\n",
    "\n",
    "b[0] = 999\n",
    "print(\"\\nArray a after b is modified:\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 2D array slicing in numpy\n",
    "\n",
    "$$\n",
    "data = \n",
    "\\begin{bmatrix}\n",
    "1& 2 & 0 \\\\\n",
    "3 & 4 & 1 \\\\\n",
    "5 & 6 & 1 \\\\\n",
    "7 & 8& 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "1. Any slicing format is start:end:step\n",
    "2. 2D array slicing format is : arr[row_slicing_format, col_slicing_format]\n",
    "3. i.e. arr[row-start:row-end:row-step , col-start:col-end:col-step]\n",
    "4. Default values: \n",
    "    - If start is not specified, default value = 0, \n",
    "    - If end is not specified, default value is last element index+1\n",
    "    - If step is not specified, default value is 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[1, 2, 0], [3, 4, 1], [5, 6, 1], [7, 8, 0]])\n",
    "print(data)\n",
    "print('------')\n",
    "# Slice the features\n",
    "print(data[:, 0]) # first feature vector\n",
    "print(data[:, 0].shape)\n",
    "\n",
    "# Slice the samples\n",
    "print(data[1, :]) # second sample vector with label\n",
    "print(data[1, :-1]) # second sample vector without its label\n",
    "print(data[1, :].shape)\n",
    "\n",
    "# Slice the output labels\n",
    "print(data[:2, -1])# output label for samples 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sample-feature-slicing\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Slicing 2D array (2D Data Matrix) as features and samples\n",
    "\n",
    "Patient dataset corresponding to 4 patients and 3 features:\n",
    "\n",
    "![Patient dataset](https://bl3302files.storage.live.com/y4mlspYO-L_1kEGpBOCUilkrcj3evQtgjGXDt6v2NgJwtsJf2OZVnwRnUht7CmW_wk8VMlMyGfhDqgRubB3pLHXAOe3r-pQ5wtYUuOqR_gsZzHWCqE2IEbhBjUZob5suLplmONyMsAjr1twDPK7eGODrKyav1dP1aX3lWx1YV0hiLvuTEZ7-GujIypTMkaSV2or?width=256&height=153&cropmode=none)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectors from the data matrix**\n",
    "\n",
    "![Patient dataset](https://bl3302files.storage.live.com/y4mTMCQdiTnIFj1IALg09CRz7pPWl0g4HpigAPbwyMmF0QNliGAgK3aEsBESo0BNFCy-0-kR6pllskO1DPVt2-76bYsQaACRWhkOebqJ545BbtWcGr1CJG72BZJPrYbQDWNAC0h1EHhpewBlORT_xtahEu-bite73OVi-4CzGeQf6GDw11H6kn72VocdC2bLAsJ?width=256&height=167&cropmode=none)\n",
    "\n",
    "1st feature vector (heart rate) for all patients:\n",
    "$$x_1 = \\begin{bmatrix}76\\\\74\\\\72\\\\78\\end{bmatrix}$$\n",
    "\n",
    "1st patient vector for all features:\n",
    "$$x^{(1)} = \\begin{bmatrix}76\\\\126\\\\38\\end{bmatrix}$$\n",
    "\n",
    "Therefore Patient Matrix can be written as \n",
    "$$ \\begin{bmatrix} {x^{(1)}}^T \\\\ {x^{(2)}}^T \\\\  {x^{(3)}}^T \\\\  {x^{(4)}}^T \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create patient data matrix\n",
    "df_patient = pd.DataFrame({'HR' : [76, 74, 72, 78],\n",
    "                           'BP' : [126, 120, 118, 136],\n",
    "                           'Temp': [38, 38, 37.5, 37]})\n",
    "\n",
    "df_patient.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_patient.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_patient)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the features\n",
    "print(X[:, 0]) # first feature vector\n",
    "print(X[:, 0].shape)\n",
    "\n",
    "# Slice the samples\n",
    "print(X[1, :]) # second sample vector with label\n",
    "print(X[1, :-1]) # second sample vector without its label\n",
    "print(X[1, :].shape)\n",
    "\n",
    "# Slice the output labels\n",
    "print(X[:2, -1])# output label for samples 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='numpy-slicing-first-ml'></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Using Numpy slicing in your first ML model training\n",
    "\n",
    "##### 6.1 Load a real dataset and apply slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a publicly available CSV format dataset to load directly in Pandas\n",
    "# Sometimes this fails. In that case load the dataset locally\n",
    "df_pima = pd.read_csv(\"https://raw.githubusercontent.com/npradaschnor/Pima-Indians-Diabetes-Dataset/master/diabetes.csv\")\n",
    "df_pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pima = pd.read_csv(\"diabetes.csv\")\n",
    "df_pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = df_pima.to_numpy()\n",
    "print(Xy.shape)\n",
    "Xy[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the combined dataset containing predictor variables and target variable\n",
    "# into predictor only and target only\n",
    "\n",
    "X = Xy[:,:-1] # Extracting predictors/features\n",
    "\n",
    "# Two different way to extract target variables\n",
    "\n",
    "# Different between two is a extra colon at the end \n",
    "# First one returns vector with unspecified column i.e. (n,) \n",
    "y = Xy[:,-1] # Right way to extract target variable from sklearn perspective (unfortunately) \n",
    "y_alt = Xy[:,-1:] #returns the column vector as a (n, 1) matrix\n",
    "\n",
    "print(X.shape) #Check the shape should be one less than Xy combined\n",
    "print(y.shape)\n",
    "print(y_alt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2. Let's do some class ratio visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are running this in Google colab, then yellowbrick may not be installed by default\n",
    "# Uncomment the line below to install yellowbrick\n",
    "#!pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: Why is this important?\n",
    "from yellowbrick.target import ClassBalance\n",
    "\n",
    "visualizer = ClassBalance(labels=[1, 0])\n",
    "visualizer.fit(y) # Fit the data to the visualizer\n",
    "visualizer.show() # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3. Apply Logistic Regression on the diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# We will restrict to these predictors \"Pregnancies\", \"Glucose\",\"BloodPressure\"\n",
    "# These are first three columns in dataset. Their indexes are 0,1,2\n",
    "#Do you recall this fit method as the training phase?\n",
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier.fit(X[:,0:3],y_alt) # This fails with a self explanatory error. Fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier.fit(X,y) #Do you recall this fit method as the training phase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict phase\n",
    "## Defining the y_pred variable for the predicting values. \n",
    "y_pred=lr_classifier.predict(X) #Can you think why this is failing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=lr_classifier.predict(X[:,0:3]) # y had actual values, y_pred has predicted values\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.4 Evaluating machine learning model & visualising metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y, y_pred, labels=lr_classifier.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lr_classifier.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "visualizer = ROCAUC(lr_classifier, classes=lr_classifier.classes_)\n",
    "visualizer.fit(X[:,0:3], y)        \n",
    "visualizer.score(X[:,0:3], y)        \n",
    "visualizer.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.model_selection import FeatureImportances\n",
    "\n",
    "viz = FeatureImportances(lr_classifier)\n",
    "viz.fit(X[:,0:3], y)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exercise1'></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Exercise1 - Manually select best features \n",
    "Given that the feature importance are as shown in the plot generated in the above cell, experiment with many combination of features and manually pick the best features to do Logistic regression. Compare the metrics you obtain with the earlier metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "## Numpy Operations: Vectorization, Universal functions & Broadcasting\n",
    "\n",
    "Flynn classification of Michael Flynn (1966) classification of architecture into \n",
    "- Single Instruction Single Data (SISD)\n",
    "- Single Instruction Multiple Data (SIMD)\n",
    "- Multiple Instruction Single Data(MISD)\n",
    "- Multiple Instruction Multiple Data (MIMD)\n",
    "\n",
    "![SISD](https://onedrive.live.com/embed?resid=A5A4158EF1352FCB%211886&authkey=%21AA5A9zUQ1erTn9A&width=400&height=400)\n",
    "![SIMD](https://onedrive.live.com/embed?resid=A5A4158EF1352FCB%211885&authkey=%21AGbJBIeOWrSjDJc&width=400&height=400)\n",
    "<br/>\n",
    "![MISD](https://onedrive.live.com/embed?resid=A5A4158EF1352FCB%211884&authkey=%21ANsxXmrwlI8bQ5w&width=400&height=400)\n",
    "![MIMD](https://onedrive.live.com/embed?resid=A5A4158EF1352FCB%211883&authkey=%21AHzM_PakrhCYjO8&width=400&height=400)\n",
    "\n",
    "1. Vectorization is a technique that leverages the Single Instruction Multiple Data (SIMD) features of CPUs or GPUs to perform multiple data operations simultaneously.\n",
    "2. SIMD brings data level parallelism to hardware level (Previously cores gave code level parallelism).\n",
    "3. Intel further provides Streaming SIMD extensions. Instruction Set Architecture (ISA) extension and vector registers in addition to data registers\n",
    "4. SIMD operations refers to a computing method that enables processing of multiple data with a single instruction. In contrast, the conventional sequential approach using one instruction to process each individual data is called scalar operations\n",
    "\n",
    "![SIMD Add](https://onedrive.live.com/embed?resid=A5A4158EF1352FCB%211881&authkey=%21AFyOOnjCQzxTC1A&width=439&height=228) \n",
    "![SIMD conditional](https://onedrive.live.com/embed?resid=A5A4158EF1352FCB%211882&authkey=%21AKFQ34NpDloQr4w&width=251&height=220)\n",
    "\n",
    "5. NumPy’s contiguous memory layout facilitates vectorized operations taking advantage of hardware support when available.\n",
    "\n",
    "References: \n",
    "1. https://learnlearn.uk/alevelcs/sisd-simd-misd-mimd/\n",
    "2. http://ftp.cvut.cz/kernel/people/geoff/cell/ps3-linux-docs/CellProgrammingTutorial/BasicsOfSIMDProgramming.html\n",
    "\n",
    "Additional Reading:\n",
    "1. https://stackoverflow.blog/2020/07/08/improving-performance-with-simd-intrinsics-in-three-use-cases/\n",
    "2. http://const.me/articles/simd/simd.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"vector-power\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Power of Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a vector a, calculate the reciprocal of all entries of a\n",
    "$$\n",
    "arr = \n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "5 \\\\\n",
    "7\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "output = \n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "1/3 \\\\\n",
    "1/5 \\\\\n",
    "1/7\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Traditional approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reciprocals(arr):\n",
    "    output = np.empty(len(arr))\n",
    "    for i in range(len(arr)):\n",
    "        output[i] = 1.0 / arr[i]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1,2,3])\n",
    "compute_reciprocals(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1\n",
    "y=1\n",
    "x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"Hello\"\n",
    "str2 = \" world\"\n",
    "str1 + str2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numpy approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1,2,3])\n",
    "1/arr # Is it just operator overloading syntax sugar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "arr = np.random.rand(10000)\n",
    "compute_reciprocals(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "arr = np.random.rand(10000)\n",
    "1/arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [1,2,3,4,5]\n",
    "\n",
    "for row_idx, row_val in enumerate(lst):\n",
    "        lst[row_idx] += 1\n",
    "\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [[1, 2, 3], [4, 5, 6]]\n",
    "\n",
    "for row_idx, row_val in enumerate(lst):\n",
    "    for col_idx, col_val in enumerate(row_val):\n",
    "        lst[row_idx][col_idx] += 1\n",
    "\n",
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List comprehension may make your code look compact, but its performance is no way comparable to numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [[1, 2, 3], [4, 5, 6]]\n",
    "[[cell + 1 for cell in row] for row in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1,2,3,4,5])\n",
    "arr = arr + 1  #this is both vectorized and broadcast with operator overloading\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "lst = np.random.rand(1000).tolist()\n",
    "\n",
    "for row_idx, row_val in enumerate(lst):\n",
    "        lst[row_idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to write custom vectorized functions with @vectorize decorator?\n",
    "# This is a topic of part 2 of Numpy tutorial \n",
    "# @vectorize \n",
    "# def my_numpy_vectorization_func():\n",
    "#     np.add(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "arr = np.random.rand(1000)\n",
    "arr = arr + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1,2,3,4,5])\n",
    "\n",
    "np.add(arr, 1) # same as arr = arr + 1\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ufunc\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Universal Functions (ufuncs) - Built-in vectorized operations\n",
    "\n",
    "1. Numpy Vectorization replaces the need for for loop. \n",
    "2. NumPy provides vectorized wrappers for performing element-wise operations implicitly via so-called ufuncs -- short for universal functions\n",
    "3. 60+ Ufuncs are available out of the box. More can be written by utilizing these\n",
    "4. ufuncs for basic arithmetic operations are add, subtract, divide, multiply, and exp\n",
    "5. NumPy uses operator overloading so that we can use mathematical operators (+, -, /, *, and **) directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 1D arrays\n",
    "arr = np.array([1,2,3,4])\n",
    "print(arr+1)\n",
    "print(arr*2)\n",
    "print(arr - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2D arrays\n",
    "arr = np.array([[1,2,3],[4,5,6]])\n",
    "#print(arr + 1)\n",
    "print(arr ** 2)\n",
    "#print(arr - 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"add-minus-multiply\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 3 basic vector operations - Scalar multiplication, Vector addition, & subtraction\n",
    "\n",
    "The simple multiplication and vector addition, subtraction are also vectorized operation with overloaded *, + and - \n",
    "\n",
    "Geometric meaning of vector addition and subtraction is covered in the ALA theory class - slides in MS Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar multiplication\n",
    "\n",
    "# heights of 5 students in inches\n",
    "height_inches = np.array([67, 62, 65, 68, 70])\n",
    "height_cm = 2.5 * height_inches #unit conversion is achieved by scalar multiplication \n",
    "height_cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Addition\n",
    "\n",
    "internal_marks = np.array([8, 10, 7.5, 10, 9]) # out of 10\n",
    "external_marks = np.array([38, 39, 37.5, 40, 29]) # out of 40\n",
    "total_marks = internal_marks + external_marks #out of 50\n",
    "total_marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector subtraction\n",
    "\n",
    "sessional1_marks = np.array([19.5, 20, 18, 17.5, 14])\n",
    "sessional2_marks = np.array([17, 20, 20, 15, 10])\n",
    "sessional1_excess_marks = sessional1_marks - sessional2_marks\n",
    "sessional1_excess_marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"masking\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Comparison operators and boolean mask based indexing\n",
    "\n",
    "1. Comparison operators provides vectorization of logical operations\n",
    "2. batch indexing option (where slicing is painful due to conditionals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1, 2, 3, 4])\n",
    "mask = arr > 2\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can combine and write as a single statement\n",
    "# This is the most common usage you will see\n",
    "arr[arr > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "~mask  #negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1, 2, 3, 4])\n",
    "(arr >= 3) | (arr < 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[(arr >= 3) | (arr < 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 A simple usage of masked indexing to fetch data specific to a label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the iris dataset to a pandas dataframe\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Add the target variable to the dataframe\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Print the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X[:,:-1]\n",
    "y=X[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[y==1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"aggr-functions\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Aggregation functions\n",
    "\n",
    "Aggregation functions reduce a \n",
    "1. 1D array to a single number\n",
    "2. 2D array to a single number or a 1D vector\n",
    "\n",
    "##### 5.1 Aggregation functions on 1D vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,4,3,2])\n",
    "print(f\"Array Sum = {np.sum(a)}\")\n",
    "print(f\"Array mean = {a.mean()}\")\n",
    "print(f\"Array Standard deviation = {a.std()}\")\n",
    "print(f\"Array max = {a.max()}\")\n",
    "print(f\"Array arg max = {a.argmax()}\")\n",
    "print(f\"Array min = {a.min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not an aggregation function, but worth mentioning\n",
    "a = np.array([100,400,300,200])\n",
    "print(f\"Array sort = {np.sort(a)}\")\n",
    "print(f\"Indices of array sort = {np.argsort(a)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2 Aggregation function on 2D vectors\n",
    "\n",
    "Consider a 2D numpy array as follows \n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1& 2 & 3 \\\\\n",
    "4 & 4 & 6\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "When applying the aggregation functions to reduce 2D or higher array, an essential component is axis\n",
    "$$ $$\n",
    "\n",
    "![Axis for numpy universal functions](https://onedrive.live.com/embed?resid=A5A4158EF1352FCB%211869&authkey=%21ALi7h-NEZyy7NWs&width=652&height=341)\n",
    "\n",
    "<br/>\n",
    "Below is an example of appying different axis for sum on 2D array\n",
    "\n",
    "![Impact of axis on np sum](https://onedrive.live.com/embed?resid=A5A4158EF1352FCB%211868&authkey=%21APztoOQGCQC-O1Q&width=1000&height=409)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3],[4,5,6]])\n",
    "print(f\"Sum without any axis = {a.sum()}\")\n",
    "print(f\"Sum without any axis = {a.sum(axis=0)}, Shape of the aggregate vector is {a.sum(axis=0).shape}\")\n",
    "print(f\"Sum without any axis = {np.sum(a, axis=1)}, Shape of the aggregate vector is {a.sum(axis=1).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"avg-patient\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Average Patient calculation\n",
    "\n",
    "![Patient dataset](https://bl3302files.storage.live.com/y4mTMCQdiTnIFj1IALg09CRz7pPWl0g4HpigAPbwyMmF0QNliGAgK3aEsBESo0BNFCy-0-kR6pllskO1DPVt2-76bYsQaACRWhkOebqJ545BbtWcGr1CJG72BZJPrYbQDWNAC0h1EHhpewBlORT_xtahEu-bite73OVi-4CzGeQf6GDw11H6kn72VocdC2bLAsJ?width=256&height=167&cropmode=none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Create patient data matrix\n",
    "df_patient = pd.DataFrame({'HR' : [76, 74, 72, 78],\n",
    "                           'BP' : [126, 120, 118, 136],\n",
    "                           'Temp': [38, 38, 37.5, 37]})\n",
    "\n",
    "df_patient.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_patient.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(X) # Is this average patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(X, axis=0) #How about this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmean = np.mean(X, axis=0)\n",
    "Xmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is also valid\n",
    "# avg_patient = (1/X.shape[0]) * np.sum(X, axis=0)\n",
    "Xmean #What does this Xmean represent geometrically?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Geometrically, average patient is the centroid of the patients when plotted in feature space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = np.array([\n",
    "    [76,126,38],[74,120,38],[72,118,37.5],[78,136,37],\n",
    "    [72,125,38],[78,119,38],[76,120,37.5],[78,130,37],\n",
    "    [76,126,38],[74,120,37],[74,120,37],[78,132,36],\n",
    "    [74,124,38],[74,118,38],[74,118,37],[78,128,35],\n",
    "\n",
    "    ])\n",
    "avg_patient = np.mean(patients, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.set_xlabel(\"Heart Rate\")\n",
    "ax.set_ylabel(\"BP\")\n",
    "ax.set_zlabel(\"Temp\")\n",
    "\n",
    "ax.scatter(patients[:,0], patients[:,1], patients[:,2]) \n",
    "ax.scatter(avg_patient[0], avg_patient[1], avg_patient[2], s=44) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"broadcasting\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Broadcasting\n",
    "\n",
    "\n",
    "Broadcasting allows us to perform vectorized operations between two arrays even if their dimensions do not match by creating implicit multidimensional\n",
    "Broadcasting on \n",
    "1. 1D array with a single number\n",
    "2. 2D array with a single vector\n",
    "\n",
    "##### 7.1 Broadcasting functions on 1D vector\n",
    "\n",
    "![Broadcasting on 1D array](https://onedrive.live.com/embed?resid=A5A4158EF1352FCB%211862&authkey=%21AEj6NJt9hcQ3N8Q&width=1000&height=236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "a+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 7.2 Broadcasting functions on 2D vector\n",
    "\n",
    "![Broadcasting on 1D array](https://onedrive.live.com/embed?resid=A5A4158EF1352FCB%211863&authkey=%21AMZiqH9BTkTFLLU&width=1000&height=345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3],[4,5,6]])\n",
    "a = np.array([1,2,3])\n",
    "X+a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Broadcast](https://numpy.org/doc/stable/_images/broadcasting_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3],[4,5,6]])\n",
    "a = np.array([1,2,3])\n",
    "X-a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to broadcast columnwise**\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1& 2 & 3 \\\\\n",
    "4 & 4 & 6\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "2\n",
    "\\end{bmatrix} ....\n",
    "\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3],[4,5,6]])\n",
    "a = np.array([1,2])\n",
    "X+a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Broadcast mismatch](https://numpy.org/doc/stable/_images/broadcasting_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3],[4,5,6]])\n",
    "a = np.array([1,2]).reshape(-1,1) #This is how we get broadcasting along axis 1\n",
    "X+a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"farthest-patient\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Farthest patient from mean patient\n",
    "\n",
    "1. This technique combines aggregation and broadcasting\n",
    "2. Used for simple outlier detection using statistical techniques\n",
    "3. Serves as basis for outlier detection in complex multivariate Gaussian distribution  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Create patient data matrix\n",
    "df_patient = pd.DataFrame({'HR' : [76, 74, 72, 78],\n",
    "                           'BP' : [126, 120, 118, 136],\n",
    "                           'Temp': [38, 38, 37.5, 37]})\n",
    "\n",
    "df_patient.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_patient.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_patient = np.mean(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.set_xlabel(\"Heart Rate\")\n",
    "ax.set_ylabel(\"BP\")\n",
    "ax.set_zlabel(\"Temp\")\n",
    "\n",
    "ax.scatter(X[:,0], X[:,1], X[:,2]) \n",
    "ax.scatter(avg_patient[0], avg_patient[1], avg_patient[2], s=44) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.1 Distance between any two patients\n",
    "\n",
    "![Patient dataset](https://bl3302files.storage.live.com/y4mlspYO-L_1kEGpBOCUilkrcj3evQtgjGXDt6v2NgJwtsJf2OZVnwRnUht7CmW_wk8VMlMyGfhDqgRubB3pLHXAOe3r-pQ5wtYUuOqR_gsZzHWCqE2IEbhBjUZob5suLplmONyMsAjr1twDPK7eGODrKyav1dP1aX3lWx1YV0hiLvuTEZ7-GujIypTMkaSV2or?width=256&height=153&cropmode=none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "patient1 = X[0]\n",
    "patient2 = X[1]\n",
    "\n",
    "# Very brute force\n",
    "col_dist_summation = 0\n",
    "for col in range(X.shape[1]): \n",
    "    col_dist_summation += (patient1[col] - patient2[col]) ** 2 # element wise subtraction and exponentiation\n",
    "\n",
    "dist = math.sqrt(col_dist_summation)\n",
    "print(f\"distance between patient1 and 2 is {dist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A little brute force \n",
    "\n",
    "patient1 = X[0]\n",
    "patient2 = X[1]\n",
    "\n",
    "difference_vector = patient1 - patient2 # vectorized subtraction instead of elementwise subtraction\n",
    "\n",
    "col_dist_summation = 0\n",
    "for col in range(X.shape[1]): \n",
    "    col_dist_summation += difference_vector[col] ** 2 #still using elementwise exponentiation\n",
    "\n",
    "dist = math.sqrt(col_dist_summation)\n",
    "print(f\"distance between patient1 and 2 is {dist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting better\n",
    "\n",
    "patient1 = X[0]\n",
    "patient2 = X[1]\n",
    "\n",
    "difference_vector = patient1 - patient2 #vectorized subtraction\n",
    "\n",
    "print(f\"difference vector is {difference_vector}\")\n",
    "\n",
    "dist = np.sqrt(np.sum(difference_vector**2)) # vectorized exponentitation instead of elementwise exponentiation\n",
    "\n",
    "print(f\"distance between patient1 and 2 is {dist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use built-in norm function\n",
    "\n",
    "patient1 = X[0]\n",
    "patient2 = X[1]\n",
    "\n",
    "difference_vector = patient1 - patient2\n",
    "\n",
    "dist = np.linalg.norm(difference_vector) #norm is the linear algebra term for vector magnitude\n",
    "print(f\"distance between patient1 and 2 is {dist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(X[0] - X[1]) # bring it down to one line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distance of any given patient from mean**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.1 Distance between any two patients\n",
    "\n",
    "![Patient dataset](https://bl3302files.storage.live.com/y4mlspYO-L_1kEGpBOCUilkrcj3evQtgjGXDt6v2NgJwtsJf2OZVnwRnUht7CmW_wk8VMlMyGfhDqgRubB3pLHXAOe3r-pQ5wtYUuOqR_gsZzHWCqE2IEbhBjUZob5suLplmONyMsAjr1twDPK7eGODrKyav1dP1aX3lWx1YV0hiLvuTEZ7-GujIypTMkaSV2or?width=256&height=153&cropmode=none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_patient = np.mean(X, axis=0)\n",
    "avg_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = X[0] #choose first patient\n",
    "mean_centrered_patient = patient - avg_patient\n",
    "\n",
    "#distance of patient 1 from average patient\n",
    "np.linalg.norm(mean_centrered_patient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is mean subtraction called mean centering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_patient = np.mean(X, axis=0)\n",
    "mean_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "ax.set_xlabel(\"Heart Rate\")\n",
    "ax.set_ylabel(\"BP\")\n",
    "ax.set_zlabel(\"Temp\")\n",
    "ax.set_title(\"Patient data scatter plot\")\n",
    "\n",
    "ax.scatter(X[:,0], X[:,1], X[:,2]) \n",
    "ax.scatter(avg_patient[0], avg_patient[1], avg_patient[2], s=44) \n",
    "\n",
    "\n",
    "ax = fig.add_subplot(122, projection='3d')\n",
    "\n",
    "ax.set_xlabel(\"Heart Rate (mean centered)\")\n",
    "ax.set_ylabel(\"BP (mean centered)\")\n",
    "ax.set_zlabel(\"Temp (mean centered)\")\n",
    "ax.set_title(\"Mean centered patient data scatter plot\")\n",
    "\n",
    "# note the use of broadcasting for mean subtraction\n",
    "ax.scatter(X[:,0]-mean_patient[0], X[:,1]-mean_patient[1], X[:,2]-mean_patient[2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.2 Finding the distance from mean patient vector for ALL patients: Traditional Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, patient in enumerate(X): #we can go over all patients one by one like this \n",
    "    print(patient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given patient data set \n",
    "$ \\begin{bmatrix}  76 & 126 & 38 \\\\ 74 & 120 & 38 \\\\ 72 & 118 & 37.5 \\\\ 78 & 136 & 37  \\end{bmatrix} $\n",
    "and average patient\n",
    "$\\begin{bmatrix} 75 \\\\ 125 \\\\ 37.25\\end{bmatrix}$, \n",
    "\n",
    "we can calculate the distance of each patient from average patient as \n",
    "\n",
    "$\\begin{bmatrix}  76 \\\\ 126 \\\\ 38 \\end{bmatrix}  - \\begin{bmatrix} 75 \\\\ 125 \\\\ 37.25\\end{bmatrix}$\n",
    "\n",
    "$\\begin{bmatrix}  74 \\\\ 120 \\\\ 38 \\end{bmatrix}  - \\begin{bmatrix} 75 \\\\ 125 \\\\ 37.25\\end{bmatrix}$,  \n",
    "\n",
    "$\\begin{bmatrix}  72 \\\\ 118 \\\\ 37.5 \\end{bmatrix}  - \\begin{bmatrix} 75 \\\\ 125 \\\\ 37.25\\end{bmatrix}$ and \n",
    "\n",
    "$\\begin{bmatrix}  78 \\\\ 136 \\\\ 37 \\end{bmatrix}  - \\begin{bmatrix} 75 \\\\ 125 \\\\ 37.25\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_patient = np.mean(X, axis=0)\n",
    "avg_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Very much brute force because we are explictly coding for each patient vector\n",
    "\n",
    "distances = np.empty(X.shape[0]) # 1D array to hold the distances of patient vector from mean vector \n",
    "\n",
    "patient0_mean_distance = np.linalg.norm(X[0] - avg_patient)\n",
    "distances[0] = patient0_mean_distance\n",
    "\n",
    "patient1_mean_distance = np.linalg.norm(X[1] - avg_patient)\n",
    "distances[1] = patient1_mean_distance\n",
    "\n",
    "patient2_mean_distance = np.linalg.norm(X[2] - avg_patient)\n",
    "distances[2] = patient2_mean_distance\n",
    "\n",
    "patient3_mean_distance = np.linalg.norm(X[3] - avg_patient)\n",
    "distances[3] = patient3_mean_distance\n",
    "\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farthest_patient_index = np.argmax(distances)\n",
    "print(f\"farthest patient from mean is {farthest_patient_index} and the patient data  is {X[farthest_patient_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put it all together and add a for loop\n",
    "distances = np.empty(X.shape[0])\n",
    "\n",
    "for i, patient in enumerate(X):\n",
    "    patient_mean_distance = np.linalg.norm(patient - avg_patient)\n",
    "    distances[i] = patient_mean_distance\n",
    "\n",
    "farthest_patient_index = np.argmax(distances)\n",
    "#print(f\"farthest patient from mean is {farthest_patient_index} and the patient data is {X[farthest_patient_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.3 Finding the distance from mean patient vector for ALL patients: Vectorized Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farthest_patient_index = np.argmax(np.linalg.norm(X - avg_patient, axis=1))\n",
    "#print(f\"farthest patient from mean is {farthest_patient_index} and the patient data is {X[farthest_patient_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{bmatrix}  76 & 126 & 38 \\\\ 74 & 120 & 38 \\\\ 72 & 118 & 37.5 \\\\ 78 & 136 & 37  \\end{bmatrix}  - \\begin{bmatrix} 75 & 125 & 37.25\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "# traditional approach, removed the print statement, bcoz timeit runs several times and floods the output with print statements\n",
    "distances = np.empty(X.shape[0])\n",
    "\n",
    "for i, patient in enumerate(X):\n",
    "    patient_mean_distance = np.linalg.norm(patient - avg_patient)\n",
    "    distances[i] = patient_mean_distance\n",
    "\n",
    "farthest_patient_index = np.argmax(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "farthest_patient_index = np.argmax(np.linalg.norm(X - avg_patient, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us dissect what just happened**\n",
    "\n",
    "$$ \\begin{bmatrix}  76 & 126 & 38 \\\\ 74 & 120 & 38 \\\\ 72 & 118 & 37.5 \\\\ 78 & 136 & 37  \\end{bmatrix}  - \\begin{bmatrix} 75 & 125 & 37.25\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are subtracting a avg_patient vector from patient matrix\n",
    "# avg patient vector is broadcasted row wise \n",
    "X - avg_patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a matrix giving the deviation of each patient from the average patient\n",
    "\n",
    "**Mean centered patient matrix**\n",
    "$$\\begin{bmatrix} 1 & 1 & 0.375 \\\\ -1 & -5 & 0.375 \\\\ -3 & -7 & -0.125 \\\\ 3 & 11 & -0.625 \\end{bmatrix}$$\n",
    "\n",
    "Now we can calculate the norm on the matrix itself. A norm is also a aggregation operation (because it reduces the three elements of a mean centered patient vector to a single number viz. the magnitude of the mean centered vector)\n",
    "\n",
    "However we do not want to calculate the norm of the entire matrix. Rather we want to calculate the norm of the mean centered patient vector. This is calculated along the columns (axis=1) and it gives us the distance of each patient from the average patient.\n",
    "$$\\begin{bmatrix} 1.46 \\\\ 5.112 \\\\ 7.616 \\\\ 11.4 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_vectors = np.linalg.norm(X - avg_patient, axis=1) #norm along column axis \n",
    "distance_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scaler-tx\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Feature transformation in sklearn\n",
    "\n",
    "1. This extends the idea of subtracting an average patient from all patients a bit further. \n",
    "2. In the process, the features are transformed\n",
    "3. Feature Transformation is an essential part of Feature Engineering as a pre cursor to applying ML algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create patient data matrix\n",
    "df_patient = pd.DataFrame({'HR' : [76, 74, 72, 78],\n",
    "                           'BP' : [126, 120, 118, 136],\n",
    "                           'Temp': [38, 38, 37.5, 37]})\n",
    "\n",
    "df_patient.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ X\\_scaled = z = \\frac{x-\\mu}{\\sigma} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"mean = {np.mean(X_scaled, axis=0)}\")\n",
    "print(f\"standard deviation = {np.std(X_scaled, axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. StandardScaler transformation made the mean = 0 and standard deviation = 1\n",
    "2. Standardization assumes the features follow Gaussian distribution and are mostly independent\n",
    "3. Removes units from features\n",
    "4. Converts into spherical gaussian distribution\n",
    "3. Standardization is same as BatchNormalization in Keras/Tensorflow\n",
    "\n",
    "Confusion: \n",
    "1. In sklearn and industry standard literature, normalization refers to another type of scaling viz MinMaxScaling\n",
    "2. This scales the data between 0 and 1\n",
    "3. We will use both in EDA in future labs\n",
    "\n",
    "$$ X\\_normalized = \\frac{X - X_{min}}{(X_{max} - X_{min})} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional Reading**\n",
    "\n",
    "Check these Scalers available in sklearn and when each is going to be used. One of the favorite questions in interviews\n",
    "\n",
    "1. StandardScaler\n",
    "2. MinMaxScaler\n",
    "3. RobustScaler\n",
    "4. MaxAbsScaler\n",
    "5. LogTransformer\n",
    "5. PowerTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"farthest-patients\"></a>\n",
    "<hr/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Calculating farthest patients from each other\n",
    "\n",
    "1. Slightly advanced topic - Only for AIML M.E.\n",
    "2. Will be covered in ALA lab using multiple vectorization techniques\n",
    "3. Many more vectorization techniques\n",
    "\n",
    "NOTE: If you are not thorough with this Numpy tutorial, all upcoming vectorization will sound alien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"farthest-patients\"></a>\n",
    "<hr/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quickstart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
